{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f3af233",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-08-10T19:31:17.756118Z",
     "iopub.status.busy": "2023-08-10T19:31:17.755705Z",
     "iopub.status.idle": "2023-08-10T19:31:17.760930Z",
     "shell.execute_reply": "2023-08-10T19:31:17.760030Z"
    },
    "papermill": {
     "duration": 0.01484,
     "end_time": "2023-08-10T19:31:17.764480",
     "exception": false,
     "start_time": "2023-08-10T19:31:17.749640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bfd23a",
   "metadata": {
    "papermill": {
     "duration": 0.003832,
     "end_time": "2023-08-10T19:31:17.772581",
     "exception": false,
     "start_time": "2023-08-10T19:31:17.768749",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "If the dataset is in a zipped,it can be unzipped by using the ZipFile module.There are other options such as unzip <filename>.zip for linux and macos.\n",
    "The dataset i'm using is readily unzipped to use.\n",
    " \n",
    "For those using google colab,it is advised to upload the dataset to google drive and mount the drive to your colab.Note that it takes a lot of times if your dataset is anywhere between medium to Large.\n",
    " \n",
    "For kaggle users,Datasets from kaggle can be added by using the add dataset option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6abdcdb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-10T19:31:17.782496Z",
     "iopub.status.busy": "2023-08-10T19:31:17.781649Z",
     "iopub.status.idle": "2023-08-10T19:31:17.785820Z",
     "shell.execute_reply": "2023-08-10T19:31:17.784989Z"
    },
    "papermill": {
     "duration": 0.010927,
     "end_time": "2023-08-10T19:31:17.787601",
     "exception": false,
     "start_time": "2023-08-10T19:31:17.776674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# with zipfile.ZipFile('/kaggle/input/dogs-vs-cats/train.zip','r') as file:\n",
    "#     file.extractall('.')\n",
    "#     print('unzipped')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f595c91c",
   "metadata": {
    "papermill": {
     "duration": 0.003783,
     "end_time": "2023-08-10T19:31:17.795568",
     "exception": false,
     "start_time": "2023-08-10T19:31:17.791785",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To label the images,we will be using flow_from_directory method,which requires the data be in a specific heirarchy<br>\n",
    "**/mainDirectory<br>\n",
    "  ----/label1<br>\n",
    "        ---------/data1<br>\n",
    "        ---------/data2<br>\n",
    "  ----/label2<br>\n",
    "        --------/data1<br>\n",
    "        --------/data2<br>**\n",
    " Since all our data is conveniently named with either a cat or dog as the starting part of the name,sorting into a heirarchy is much easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efb4f73f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-10T19:31:17.805460Z",
     "iopub.status.busy": "2023-08-10T19:31:17.804666Z",
     "iopub.status.idle": "2023-08-10T19:31:17.809416Z",
     "shell.execute_reply": "2023-08-10T19:31:17.808579Z"
    },
    "papermill": {
     "duration": 0.011628,
     "end_time": "2023-08-10T19:31:17.811324",
     "exception": false,
     "start_time": "2023-08-10T19:31:17.799696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import cv2,os,shutil\n",
    "# datasetdir = '/kaggle/working/train'\n",
    "# cat_dir = os.path.join(datasetdir, 'cats')\n",
    "# dog_dir = os.path.join(datasetdir, 'dogs')\n",
    "# os.makedirs(cat_dir, exist_ok=True)\n",
    "# os.makedirs(dog_dir, exist_ok=True)\n",
    "# for filename in os.listdir(datasetdir):\n",
    "#     if filename.startswith('cat'):\n",
    "#         src_path = os.path.join(datasetdir, filename)\n",
    "#         shutil.move(src_path, cat_dir)\n",
    "# #         print(f\"Moved {filename} to cats directory\")\n",
    "#     elif filename.startswith('dog'):\n",
    "#         src_path = os.path.join(datasetdir, filename)\n",
    "#         shutil.move(src_path, dog_dir)\n",
    "# #         print(f\"Moved {filename} to dogs directory\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260eb833",
   "metadata": {
    "papermill": {
     "duration": 0.00383,
     "end_time": "2023-08-10T19:31:17.819260",
     "exception": false,
     "start_time": "2023-08-10T19:31:17.815430",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As a rule of the thumb, 20% of the data will be reserved for validation.\n",
    "ImageDataGen is a data generator for the training data.\n",
    "* Flow_from_directory method reads and preprocesses the images from the specified directory.\n",
    "* Target_size (hyperparameter) resizes the images to a size of (200, 200) pixels. \n",
    "* Batch_size (hyperparameter) determines how many images are included in each batch during training.This batch_size is highly proportional to the learning_rate. \n",
    "* Classes specifies the class labels for the dataset ('dogs' and 'cats'). \n",
    "* The subset parameter is set to 'training' to indicate that this generator is for the training subset of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d380ce2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-10T19:31:17.828851Z",
     "iopub.status.busy": "2023-08-10T19:31:17.828308Z",
     "iopub.status.idle": "2023-08-10T19:31:29.097696Z",
     "shell.execute_reply": "2023-08-10T19:31:29.096732Z"
    },
    "papermill": {
     "duration": 11.27662,
     "end_time": "2023-08-10T19:31:29.099909",
     "exception": false,
     "start_time": "2023-08-10T19:31:17.823289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6404 images belonging to 2 classes.\n",
      "Found 1601 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "datasetdir = '/kaggle/input/cat-and-dog/training_set/training_set'\n",
    "ImageDataGen = tf.keras.preprocessing.image.ImageDataGenerator(validation_split= 0.2)\n",
    "train_generator = ImageDataGen.flow_from_directory(directory = datasetdir, target_size=(200,200), batch_size=25, classes = ('dogs','cats'), subset= 'training')\n",
    "val_generator = ImageDataGen.flow_from_directory(directory = datasetdir, target_size=(200,200), batch_size=25, classes = ('dogs','cats'), subset= 'validation')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faf1cf0",
   "metadata": {
    "papermill": {
     "duration": 0.004529,
     "end_time": "2023-08-10T19:31:29.109171",
     "exception": false,
     "start_time": "2023-08-10T19:31:29.104642",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Sequential model is a linear stack of layers.\n",
    "\n",
    "* This architecture has three sets of convolutional layers, each followed by batch normalization, max pooling, and dropout layers. These layers help the model learn hierarchical features from the input images.\n",
    "\n",
    "* Flattening converts the output into 1D array.\n",
    "\n",
    "* Two dense layers are added with ReLU activation, batch normalization, and dropout. The first dense layer has 512 units, and the second dense layer has 2 units with a softmax activation(function that scales numbers/logits into probabilities).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f19e1937",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-10T19:31:29.120221Z",
     "iopub.status.busy": "2023-08-10T19:31:29.118982Z",
     "iopub.status.idle": "2023-08-10T19:31:32.355472Z",
     "shell.execute_reply": "2023-08-10T19:31:32.354723Z"
    },
    "papermill": {
     "duration": 3.269739,
     "end_time": "2023-08-10T19:31:32.383271",
     "exception": false,
     "start_time": "2023-08-10T19:31:29.113532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 198, 198, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 198, 198, 32)     128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 99, 99, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 99, 99, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 97, 97, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 97, 97, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 48, 48, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 48, 48, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 46, 46, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 46, 46, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 23, 23, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 23, 23, 128)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 67712)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               34669056  \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,765,761\n",
      "Trainable params: 34,764,289\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,\\\n",
    "     Dropout,Flatten,Dense,Activation,\\\n",
    "     BatchNormalization\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Conv2D(32,(3,3),activation='relu',input_shape=(200,200,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1,activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "  optimizer='adam',metrics=['accuracy']) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac922420",
   "metadata": {
    "papermill": {
     "duration": 0.00792,
     "end_time": "2023-08-10T19:31:32.399875",
     "exception": false,
     "start_time": "2023-08-10T19:31:32.391955",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* EarlyStopping is a callback that stops training if a metric (such as validation loss or accuracy) reamins at a saturated level for a certain number of epochs (here 10)\n",
    "* ReduceLROnPlateau is another callback that slowly reduces the learning rate when the aforementioned saturation is observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f48ae3f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-10T19:31:32.417267Z",
     "iopub.status.busy": "2023-08-10T19:31:32.416941Z",
     "iopub.status.idle": "2023-08-10T19:31:32.422429Z",
     "shell.execute_reply": "2023-08-10T19:31:32.421384Z"
    },
    "papermill": {
     "duration": 0.016703,
     "end_time": "2023-08-10T19:31:32.424498",
     "exception": false,
     "start_time": "2023-08-10T19:31:32.407795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "earlystop = EarlyStopping(patience = 10)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_acc',patience = 2,verbose = 1,factor = 0.5,min_lr = 0.01)\n",
    "callbacks = [earlystop,learning_rate_reduction]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4dc6b0",
   "metadata": {
    "papermill": {
     "duration": 0.008136,
     "end_time": "2023-08-10T19:31:32.440951",
     "exception": false,
     "start_time": "2023-08-10T19:31:32.432815",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Epoch specifies the number of times the model will iterate over the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c425ca3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-10T19:31:32.458440Z",
     "iopub.status.busy": "2023-08-10T19:31:32.458127Z",
     "iopub.status.idle": "2023-08-10T19:54:08.342296Z",
     "shell.execute_reply": "2023-08-10T19:54:08.341203Z"
    },
    "papermill": {
     "duration": 1355.895852,
     "end_time": "2023-08-10T19:54:08.345016",
     "exception": false,
     "start_time": "2023-08-10T19:31:32.449164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-10 19:31:34.389509: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 32s 81ms/step - loss: 0.7412 - accuracy: 0.5000 - val_loss: 1.7185 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 21s 82ms/step - loss: 0.7012 - accuracy: 0.5000 - val_loss: 2.8022 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 21s 82ms/step - loss: 0.6960 - accuracy: 0.5000 - val_loss: 4.1602 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 21s 82ms/step - loss: 0.6942 - accuracy: 0.5000 - val_loss: 5.5312 - val_accuracy: 0.5000\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 21s 81ms/step - loss: 0.6935 - accuracy: 0.5000 - val_loss: 6.0302 - val_accuracy: 0.5000\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 22s 83ms/step - loss: 0.7052 - accuracy: 0.5000 - val_loss: 0.7585 - val_accuracy: 0.5000\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 22s 85ms/step - loss: 0.6944 - accuracy: 0.5000 - val_loss: 0.7156 - val_accuracy: 0.5000\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 21s 81ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.7342 - val_accuracy: 0.5000\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 22s 82ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.8837 - val_accuracy: 0.5000\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 22s 84ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 1.1520 - val_accuracy: 0.5000\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 22s 84ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 1.4188 - val_accuracy: 0.5000\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 18s 70ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 1.4245 - val_accuracy: 0.5000\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 19s 72ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 1.3396 - val_accuracy: 0.5000\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 21s 81ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 1.5406 - val_accuracy: 0.5000\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 21s 81ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 2.1812 - val_accuracy: 0.5000\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 21s 82ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 1.8432 - val_accuracy: 0.5000\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 21s 81ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 1.7573 - val_accuracy: 0.5000\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 18s 69ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 1.9246 - val_accuracy: 0.5000\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 21s 82ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 1.7153 - val_accuracy: 0.5000\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 19s 72ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 1.5731 - val_accuracy: 0.5000\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 22s 83ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 1.3536 - val_accuracy: 0.5000\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 17s 65ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 1.3756 - val_accuracy: 0.5000\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 21s 79ms/step - loss: 0.6938 - accuracy: 0.5000 - val_loss: 1.4222 - val_accuracy: 0.5000\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 21s 82ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 2.1444 - val_accuracy: 0.5000\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 22s 84ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 1.5614 - val_accuracy: 0.5000\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 21s 81ms/step - loss: 0.6939 - accuracy: 0.5000 - val_loss: 0.9806 - val_accuracy: 0.5000\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 22s 83ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.9043 - val_accuracy: 0.5000\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 21s 80ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.9148 - val_accuracy: 0.5000\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 16s 62ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.9448 - val_accuracy: 0.5000\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 21s 82ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.9229 - val_accuracy: 0.5000\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 21s 80ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.9193 - val_accuracy: 0.5000\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 22s 85ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.9073 - val_accuracy: 0.5000\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 21s 81ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.9798 - val_accuracy: 0.5000\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 22s 84ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 1.1711 - val_accuracy: 0.5000\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 21s 82ms/step - loss: 0.6943 - accuracy: 0.5000 - val_loss: 0.7288 - val_accuracy: 0.5000\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 22s 83ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.7046 - val_accuracy: 0.5000\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 21s 81ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.7185 - val_accuracy: 0.5000\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 22s 83ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.7019 - val_accuracy: 0.5000\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 22s 85ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.7108 - val_accuracy: 0.5000\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 16s 62ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.7114 - val_accuracy: 0.5000\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 21s 82ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.7172 - val_accuracy: 0.5000\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 21s 82ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.7128 - val_accuracy: 0.5000\n",
      "Epoch 43/50\n",
      "257/257 [==============================] - 21s 80ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.7120 - val_accuracy: 0.5000\n",
      "Epoch 44/50\n",
      "257/257 [==============================] - 21s 81ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6966 - val_accuracy: 0.5000\n",
      "Epoch 45/50\n",
      "257/257 [==============================] - 21s 80ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6980 - val_accuracy: 0.5000\n",
      "Epoch 46/50\n",
      "257/257 [==============================] - 19s 73ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.7027 - val_accuracy: 0.5000\n",
      "Epoch 47/50\n",
      "257/257 [==============================] - 21s 81ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.7040 - val_accuracy: 0.5000\n",
      "Epoch 48/50\n",
      "257/257 [==============================] - 22s 84ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.7000 - val_accuracy: 0.5000\n",
      "Epoch 49/50\n",
      "257/257 [==============================] - 21s 80ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6966 - val_accuracy: 0.5000\n",
      "Epoch 50/50\n",
      "257/257 [==============================] - 21s 81ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6968 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator, \n",
    "    validation_data = val_generator,\n",
    "    workers=10,\n",
    "    epochs=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11c066e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-10T19:54:09.878861Z",
     "iopub.status.busy": "2023-08-10T19:54:09.877807Z",
     "iopub.status.idle": "2023-08-10T19:54:13.635173Z",
     "shell.execute_reply": "2023-08-10T19:54:13.633968Z"
    },
    "papermill": {
     "duration": 4.553514,
     "end_time": "2023-08-10T19:54:13.637223",
     "exception": false,
     "start_time": "2023-08-10T19:54:09.083709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 4s 55ms/step - loss: 0.6968 - accuracy: 0.5000\n",
      "Validation Loss: 0.6967554092407227\n",
      "Validation Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "evaluation = model.evaluate(val_generator)\n",
    "print(\"Validation Loss:\", evaluation[0])\n",
    "print(\"Validation Accuracy:\", evaluation[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da16451d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-10T19:54:15.179061Z",
     "iopub.status.busy": "2023-08-10T19:54:15.178631Z",
     "iopub.status.idle": "2023-08-10T19:54:16.049839Z",
     "shell.execute_reply": "2023-08-10T19:54:16.048764Z"
    },
    "papermill": {
     "duration": 1.66578,
     "end_time": "2023-08-10T19:54:16.052282",
     "exception": false,
     "start_time": "2023-08-10T19:54:14.386502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save(\"model1_catsVSdogs_10epoch.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1392.774286,
   "end_time": "2023-08-10T19:54:20.397363",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-10T19:31:07.623077",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
